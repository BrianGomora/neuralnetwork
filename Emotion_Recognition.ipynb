{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Emotion_Recognition.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPOvwqU8yQdR2XJV1ij88LV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BrianGomora/neuralnetwork/blob/main/Emotion_Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lyA0jJ4CtZn9"
      },
      "source": [
        "Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knICLrGRtQ1e"
      },
      "source": [
        "# Libraries for data visualization and analysis\n",
        "import pandas as pd\n",
        "import numpy as n\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import random \n",
        "\n",
        "\n",
        "# Libraries for deep learning \n",
        "import keras\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers.core import Flatten,Dense,Dropout,Activation \n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers.convolutional import Convolution2D, MaxPooling2D,ZeroPadding2D\n",
        "#from keras.optimizers import SGD, Adam, RMSprop\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "\n",
        "\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6wUY9AxthYk"
      },
      "source": [
        "Mounting drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BERUJBqXtlsD",
        "outputId": "0c99ab41-4500-49ee-8ea4-17482a83c49f"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "folder_path = 'gdrive/My Drive/Emotion/'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTnRbA7vtsre"
      },
      "source": [
        "IMAGES FROM DISGUST TRAINING DATASET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OT9kBQFwt3d0"
      },
      "source": [
        "image_size = 48\n",
        "\n",
        "expression = \"disgust\"\n",
        "plt.style.use(\"dark_background\")\n",
        "plt.figure(figsize= (12,12))\n",
        "for i in range(1,10,1):\n",
        "  plt.subplot(3,3,i)\n",
        "  img = load_img(folder_path +\"trainDATA/\" + expression+ \"/\" + os.listdir(folder_path + \"trainDATA/\" + expression)[i], target_size=(image_size, image_size))\n",
        "  plt.imshow(img)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1HMAaYKt-X3"
      },
      "source": [
        "DATA AUGMENTATION - GENERATING MORE DATA FOR TRAINING for generalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcvPnzOhuIW0"
      },
      "source": [
        "batch_size = 16   #number of images per iteration or 64\n",
        "image_size = 48\n",
        "\n",
        "\n",
        "imagedatagen_train = ImageDataGenerator(rescale= 1./255,\n",
        "                                        rotation_range=30,\n",
        "                                        shear_range=0.3,\n",
        "                                        zoom_range=0.3,\n",
        "                                        horizontal_flip= True,\n",
        "                                        height_shift_range=0.4,\n",
        "                                        width_shift_range =0.4)\n",
        "\n",
        "imagedatagen_val = ImageDataGenerator(horizontal_flip = True)\n",
        "\n",
        "train_imageSET = imagedatagen_train.flow_from_directory(folder_path + \"EtrainDATA\",\n",
        "                                                  target_size = (image_size,image_size),\n",
        "                                                  color_mode = 'grayscale',\n",
        "                                                  batch_size = batch_size,\n",
        "                                                  class_mode = \"categorical\",\n",
        "                                                  shuffle = True)\n",
        "\n",
        "test_imageSET = imagedatagen_val.flow_from_directory(folder_path + \"EtestDATA\",\n",
        "                                                  target_size = (image_size,image_size),\n",
        "                                                  color_mode ='grayscale',\n",
        "                                                  batch_size = batch_size,\n",
        "                                                  class_mode = \"categorical\",\n",
        "                                                  shuffle = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oK4sRk5luNhO"
      },
      "source": [
        "BUILDING THE CONVOLUTIONAL NEURAL NETWORK"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsoQm-YDuQMW"
      },
      "source": [
        "num_classes = 7 \n",
        "model = Sequential()\n",
        "random.seed()\n",
        "\n",
        "#1st CNN layer \n",
        "model.add(Convolution2D(254,(3,3),padding =\"same\", input_shape= (48,48,1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size= (2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "#2nd CNN layer \n",
        "model.add(Convolution2D(252,(3,3),padding =\"same\"))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size= (2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "#3Rd CNN layer \n",
        "model.add(Convolution2D(512,(3,3),padding =\"same\"))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size= (2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "#4th CNN layer \n",
        "model.add(Convolution2D(512,(3,3),padding =\"same\"))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size= (2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "# Fully connected 1st  Layer\n",
        "model.add(Dense(256))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# Fully connected 2nd  Layer\n",
        "model.add(Dense(512))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Dense(num_classes, activation= 'softmax'))\n",
        "\n",
        "opt = Adam(lr = 0.2)\n",
        "model.compile(optimizer = opt,loss='categorical_crossentropy', metrics = [\"accuracy\"])\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axWykTVYuXVZ"
      },
      "source": [
        "TRAINING AND VALIDATION WITH CNN MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfGpRQNvuYeW"
      },
      "source": [
        "from keras.optimizers import Adam, RMSprop\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "epochs = 1000\n",
        "steps_per_epoch = train_imageSET.n/ train_imageSET.batch_size\n",
        "validation_steps = test_imageSET.n/ test_imageSET.batch_size\n",
        "\n",
        "\n",
        "\n",
        "checkpoint = ModelCheckpoint(\"./model_weights.h5\",monitor = \"val_loss\",\n",
        "                             save_weights_only = True, mode= 'max',verbose = 1)\n",
        "\n",
        "\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss',factor = 0.1,patience = 2,min_lr=0.00001,\n",
        "                              mode='auto')\n",
        "\n",
        "callback_list = [checkpoint,reduce_lr]\n",
        "\n",
        "history = model.fit(\n",
        "    x = train_imageSET,\n",
        "    steps_per_epoch = steps_per_epoch,\n",
        "    epochs = epochs, \n",
        "    validation_data = test_imageSET,\n",
        "    validation_steps = validation_steps,\n",
        "    callbacks = callback_list \n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZYo7NonugI_"
      },
      "source": [
        "PLOT ACCURACY AND LOSS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GcnptMzuhOe"
      },
      "source": [
        "plt.style.use('dark_background')\n",
        "\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.subplot(1,2,2)\n",
        "plt.subtitle('Optimizer:Adam', fontsize=10)\n",
        "plt.ylabel('Loss',fontsize=16)\n",
        "plt.plot(history.history['loss'],label = 'Training Loss')\n",
        "plt.plot(history.history['val_loss'],label = 'Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.ylabel('Accuracy'fontsize = 16)\n",
        "plt.plot(history.history['accuracy'],label = 'Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'],label = 'Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V44_eV7GunCh"
      },
      "source": [
        "REPRESENT MODEL AS JSON STRING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3fvfVxyun_s"
      },
      "source": [
        "fer_json = model.to_json()\n",
        "with open('fer.json','w') as json_file:\n",
        "  json_file.write(fer_json)\n",
        "model.save_weights('fer.h5')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}